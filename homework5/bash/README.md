Результат записывается в res_bash.txt.  
Файл с логами должен находиться в папке bash
### Общее количество запросов
1) читаем файл (cat "$log")
2) считаем к-во строк в файле( wc -l ) 
3) записываем результат
### Общее количество запросов по типу
1) читаем файл (cat "$log")
2) берём 6 столбец (awk '{print $6}')
3) отсеиваем результаты длиной > 12 (awk 'length($0) < 12') (т.к. там есть какая-то не понятная строчка)
4) убираем 1-й символ (например из "POST убираем ")
5) сортирум все значения (sort) для использования группировки (uniq -c)
6) записываем результат
### Топ 10 самых частых запросов
1) читаем файл (cat "$log")
2) берём 7 столбец ( awk '{print $7}')
3) получаем path ( grep -Po '[^?#]*' ) p.s. не работет
4) Сортируем, группируем, опять сортируем уже по значениям (sort -n -r)
5) берём первые 10 результатов (head -n 10)
6) записываем результат
### Топ 5 самых больших по размеру запросов, которые завершились клиентской (4ХХ) ошибкой
1) читаем файл (cat "$log")
2) если статус код начинается в '4', то берём url, status_code, byte_size, ip ( awk '{if ($9 ~ /4../) print $7, $9, $10, $1}')
3) сторируем по 3-ему столбцу (sort -nrk3)
4) берём первые 5 результатов (head -n 5)
5) записываем результат
### Топ 5 пользователей по количеству запросов, которые завершились серверной (5ХХ) ошибкой
1) читаем файл (cat "$log")
2) если статус код начинается в '5', то берём ip ( awk '{if ($9 ~ /5../) print $1}' )
3) сортируем, группируем, опять сортируем уже по значениям ( sort | uniq -c | sort -nr )
4) берём первые 5 результатов (head -n 5)
5) записываем результат
